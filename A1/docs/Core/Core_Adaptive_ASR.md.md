---
tags: [core, stt, audio]
---

# ðŸ‘‚ Core: Adaptive ASR

A1 uses a multi-stage audio pipeline known as **Adaptive Ear**.

## ðŸŽ›ï¸ The Pipeline

```mermaid
flowchart LR
    Mic[ðŸŽ™ï¸ Stream] --> VAD{Energy > Threshold?}
    
    subgraph "Fast Path (CPU)"
        VAD -- No --> Drop[ðŸ—‘ï¸ Drop]
        VAD -- Yes --> Wake[ðŸ”” Vosk Check]
    end
    
    subgraph "Deep Path (GPU)"
        Wake -- "Hey A1" --> Rec[ðŸ”´ Record 5s]
        Rec --> Whisper[ðŸ“ Whisper Small]
        Rec --> ID[ðŸ†” SpeechBrain ID]
    end
    
    Whisper --> Merge(ðŸ§© Synthesis)
    ID --> Merge
    Merge --> Output[Generic Text]
```

## ðŸ—£ï¸ Multilingual Support (Context Priming)

We "hack" Whisper by injecting a system prompt containing Tanglish keywords before every transcription.

| Language | User Says | Whisper Hears |
| :--- | :--- | :--- |
| **English** | "Open the terminal." | `Open the terminal.` |
| **Tanglish** | "Terminal open pannu." | `Terminal open pannu.` |
| **Tamil** | "Mani enna?" | `Mani enna?` |

## ðŸ†” Speaker Verification
Uses **ECAPA-TDNN** to compare voice embeddings.
- **Verified**: `Cosine Sim > 0.75`
- **Unverified**: `Cosine Sim < 0.75` (Restricted access)

---
## ðŸ•¸ï¸ Connections
- Feeds text into [[Core/Core_Router|Router]].
- Uses [[Configuration/Voice_Enrollment|Voice Enrollment]] profile.
- See [[Design/Threat_Model#1. Voice Command Injection|Security Risks]].

[[00_Index|ðŸ”™ Return to Index]]
